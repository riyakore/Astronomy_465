\documentclass[linenumbers,twocolumn]{aastex631}
\usepackage[utf8]{inputenc}
\usepackage{natbib}
\setcitestyle{round}
\usepackage{amsmath,amssymb}
\usepackage{afterpage}
\usepackage{xcolor}
\usepackage[caption=false]{subfig}
\usepackage{soul}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{graphicx}

\newcommand{\hi}{{\rm H\,{\small I}}}
\newcommand{\kms}{\ensuremath{{\rm km~s^{-1}}}}
\newcommand{\persc}{\ensuremath{{\rm cm^{-2}}}}
\newcommand{\msun}{\ensuremath{M_{\odot}}}

\begin{document}

\title{Astron 465 Radio Lab 2: Characterizing a Radio Telescope - Noise and Temperature Calibration}

\author[0000-0002-3418-7817]{Riya Kore}
\affiliation{University of Wisconsin--Madison, Department of Astronomy, 475 N Charter St, Madison, WI 53703, USA}

\section{Introduction}

In radio astronomy, the power received from astronomical sources is measured in terms of the energy detected by a radio telescope over a specific range of frequencies. These radio signals are extremely faint, so it is essential to convert the detected power into a more interpretable scale. This is achieved by expressing the power in terms of an equivalent noise temperature called the antenna temperature ($T_{a}$). The antenna temperature represents the temperature of a hypothetical blackbody that would emit the same amount of power as the observed radio signal. Using this temperature scale is practical because it allows astronomers to infer physical properties like the temperature of the emitting gas or the intensity of background radiation. The power ($P$) collected by a radio telescope is closely related to the antenna temperature ($T_{a}$) through Boltzmann's constant ($k_{B}$). The relationship is given by

\[
T_{a} = \frac{P}{k_{B}}
\]
where $k_{B}$ is Boltzmann's constant ($1.38 \times 10^{-23} \ \text{J/K}$) and $P$ represents the power measured in units of watts per hertz ($\text{W/Hz}$). This equation converts the power measured by the telescope into a temperature equivalent. This temperature-based representation simplifies the analysis of radio signals by providing a direct measure of the energy from astronomical sources. The power is initially collected as electromagnetic radiation by the telescope’s antenna and must be converted through several components of the SRT system to derive a usable signal for analysis. \\

The primary aim of this lab is to characterize the system temperature ($T_{\text{sys}}$) of the Small Radio Telescope (SRT) through calibration using a noise diode and comparison with the system's reported values. By analyzing the observed 21 cm hydrogen (\hi) line spectrum and using the calibration techniques, we seek to verify the accuracy of the SRT's noise measurements. This will allow us to assess the effectiveness of the SRT in detecting faint radio signals and its alignment with professional data, such as the Leiden-Dwingeloo Survey (LDS).

\subsection{System Temperature ($T_{\text{sys}}$) and Its Importance}

System temperature ($T_{\text{sys}}$) is a critical parameter that describes the noise characteristics of a radio telescope. It encompasses all sources of noise that contribute to the measured signal, including receiver noise, atmospheric noise, and noise from celestial sources. Receiver temperature ($T_{\text{rx}}$) accounts for the noise generated by the telescope's internal electronics, such as amplifiers and mixers, typically around 200 K for the SRT. Atmospheric temperature ($T_{\text{atm}}$) represents noise caused by the Earth's atmosphere, which tends to increase with higher frequencies but remains relatively low around 1.42 GHz, the frequency of the hydrogen line. Celestial contributions ($T_{\text{cel}}(\nu)$) include noise from cosmic sources like the cosmic microwave background (CMB) radiation, which is approximately 2.73 K, and synchrotron radiation from the Milky Way. The total system temperature is calculated as the sum of these contributions:
\[
T_{\text{sys}} = T_{\text{rx}} + T_{\text{atm}} + T_{\text{cel}}(\nu)
\]
where $\nu$ denotes the observing frequency. Accurately determining $T_{\text{sys}}$ is essential, as it directly affects the ability of the radio telescope to distinguish weak astronomical signals from background noise.

 \subsection{Calibration Process for Determining $T_{\text{sys}}$}

To accurately measure $T_{\text{sys}}$, the SRT uses a calibration technique involving a noise diode with a known temperature ($T_{\text{cal}} = 103 \ \text{K}$). The noise diode injects a reference noise signal into the system, and the resulting voltage response is recorded. This calibration process involves two key measurements: $V_{\text{cal}}$, which is the voltage recorded when the calibration diode is ON and injecting additional power, and $V_{\text{off}}$, the voltage recorded when the diode is OFF, representing the baseline noise of the system. These voltages are related to the power and system temperature through the following equations:

\[
V_{\text{cal}} = \alpha G k_{B} \Delta \nu (T_{\text{cal}} + T_{\text{sys}})
\]
\[
V_{\text{off}} = \alpha G k_{B} \Delta \nu T_{\text{sys}}
\]

where $\alpha$ is the responsivity of the receiver, which converts power into voltage (measured in $\text{V/W}$), $G$ is the gain of the receiver, a dimensionless value representing the amplification of the input signal, $\Delta \nu$ is the observing bandwidth (in Hz), and $k_{B}$ is Boltzmann's constant. By taking the ratio of these two measurements and rearranging, we derive an expression for the system temperature:
\begin{equation}
    T_{\text{sys}} = \frac{V_{\text{off}}}{V_{\text{cal}} - V_{\text{off}}} T_{\text{cal}}
\end{equation}

This equation shows how the system temperature can be inferred using the known temperature of the noise diode and the observed voltages. The calibration allows us to account for the noise introduced by the system, enabling more accurate measurements of faint astronomical signals.

\subsection{Estimating $T_{\text{sys}}$ Using RMS Noise}

Another method for estimating $T_{\text{sys}}$ involves measuring the root-mean-square (RMS) noise, which quantifies the fluctuations in the power measurements due to system noise. The RMS noise ($\sigma_{T}$) is calculated using the formula
\begin{equation}
    \sigma_{T} = \sqrt{\frac{1}{N} \sum_{i=1}^{N} x_{i}^{2}}
\end{equation} \\
where $x_{i}$ represents individual power measurements and $N$ is the total number of samples. The RMS noise is directly related to $T_{\text{sys}}$ through the radiometer equation:
\begin{equation}
    \sigma_{T} = \frac{T_{\text{sys}}}{\sqrt{\Delta \nu T}}
\end{equation} 
where $\sigma_{T}$ represents the RMS noise, $\Delta \nu$ is the frequency resolution (Hz), and $T$ is the integration time (seconds). This relationship implies that a lower system temperature and a longer integration time will reduce the RMS noise, allowing for the detection of weaker astronomical signals. This relationship is fundamental in radio astronomy, as it enables astronomers to optimize observations by adjusting integration times and frequency resolutions to achieve the desired sensitivity.

\subsection{The Significance of the 21 cm Hydrogen Line and the Leiden-Dwingeloo Survey (LDS)}

The 21 cm hydrogen (\hi) line is an important spectral feature in radio astronomy, resulting from a hyperfine transition in the ground state of neutral hydrogen atoms. When the electron in a hydrogen atom flips its spin relative to the proton, it emits a photon at a wavelength of 21 cm (1420.4 MHz). This emission allows astronomers to study the distribution of neutral hydrogen in galaxies, including mapping the structure of the Milky Way. The 21 cm line is particularly valuable because hydrogen is the most abundant element in the universe, and the 21 cm line enables detailed mapping of the distribution of cold, neutral gas. This line provides precise velocity information through Doppler shifts, which is crucial for studying the rotation curves of galaxies. It allows astronomers to probe regions of space where hydrogen gas is not ionized, revealing the structure of the interstellar medium. \\

The Leiden-Dwingeloo Survey (LDS) is a significant reference point for studies involving the 21 cm hydrogen line. Conducted in the 1990s using the Dwingeloo Radio Observatory in the Netherlands, this survey mapped the neutral hydrogen (\hi) distribution in the northern sky, covering the range of Galactic latitudes. The LDS has provided a comprehensive view of the structure and kinematics of the Milky Way's hydrogen distribution, offering data that are essential for understanding large-scale structures in our galaxy. The survey data serves as a benchmark for calibrating and validating observations made with smaller instruments like the SRT. By comparing the SRT’s observations to the LDS, we can evaluate the accuracy of the SRT's measurements and ensure that the SRT is capable of producing data consistent with larger, more sensitive surveys. This comparison provides an important validation of the SRT's performance, helping to ensure that the data it gathers can be used confidently in further studies.

\section{Observations} \label{sec:observations}

\subsection{Observing Script and Data Collection}

To collect the data for this lab, we used a command file that controlled the operations of the Small Radio Telescope (SRT) to observe the 21-cm hydrogen line. The SRT was directed to a position at Galactic longitude 110° and latitude 0°, allowing us to focus on a region within the Galactic plane. The command file used for this observation is shown in Figure \ref{fig:cmdfile} below.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.2\textwidth]{cmd_file.png}
    \caption{Command file used for SRT observations.}
    \label{fig:cmdfile}
\end{figure}

The command \texttt{record lab2.rad} initializes the data file named \textit{lab2.rad} to store our observations. The \texttt{freq 1420.405 4} command sets the observing frequency to 1420.4 MHz, the precise frequency of the 21-cm line of neutral hydrogen (HI). Mode ``4" specifies that the observation spans 156 frequency bins, each with a resolution of 0.0078125 MHz, allowing for high-resolution spectral analysis. Next, \texttt{galactic 110.0 0.0} points the SRT to a Galactic coordinate of longitude 110° and latitude 0°. The \texttt{offset 0.0 30} command adjusts the elevation by 30° to perform calibration with the \texttt{noisecal} command, which injects a known noise signal into the system. This calibration is essential for determining the system temperature ($T_{\text{sys}}$). After the calibration, \texttt{offset 0.0 0.0} moves the telescope back to its original position in the Galactic plane to continue data collection. The \texttt{:600} command specifies an integration time of 600 seconds; however, the effective integration time is 600/15 = 40 seconds, as the SRT requires time to collect and transfer data. Finally, the \texttt{roff} command ends the recording, saving the observation session.

\subsection{Integration Time, Frequency, and Scans}

In this observation, the SRT was centered at the frequency of 1420.4 MHz, corresponding to the hyperfine transition of neutral hydrogen atoms. The nominal integration time was set to 600 seconds, but due to the 1:15 ratio between data collection and transfer time, the actual integration time per scan was 40 seconds. This duration provides enough time for the telescope to gather the signal from the hydrogen emission line while minimizing noise. The frequency range is divided into 156 channels with a resolution of 0.0078125 MHz, allowing for a detailed examination of the hydrogen line profile.

\subsection{Components Involved in Signal Processing}

The main components of the SRT involved in collecting and processing the radio signals include the L-band Probe, Low Noise Amplifier (LNA), Mixer, Intermediate Frequency (IF) Amplifier, and Square Law Detector. The L-band Probe and Feedhorn focus the incoming radio waves, directing them to the receiver. This process is crucial during the initial data acquisition phase when the telescope is pointed at the specified Galactic coordinates. Once the feedhorn captures the signal, the Low Noise Amplifier (LNA) amplifies these weak radio waves, making them strong enough for further processing. This amplification is particularly important to ensure that the noise from the receiver does not dominate the weak astronomical signals. The Mixer, combined with a Local Oscillator, then converts the incoming signal frequency to an intermediate frequency (IF). This conversion helps shift the relevant spectral line into an optimal range for further analysis as the SRT tunes into the 1420.4 MHz frequency. The IF Amplifier and Filter further amplify the IF signal and filter out any unwanted noise, a critical step during the integration phase as the SRT records the HI spectrum over the specified duration. Finally, the Square Law Detector converts the power of the amplified signals into a voltage, which is then digitized. This process is especially important during the \texttt{noisecal} command, where the detector outputs the voltage values needed to compute the system temperature ($T_{\text{sys}}$).

\section{Data analysis} 
\label{sec:results}

In this section, we analyze the data collected using the Small Radio Telescope (SRT) and compare it with the professional data from the Leiden-Dwingeloo Survey (LDS). The analysis includes reading the SRT data, processing the hydrogen line spectrum, comparing it with professional data, and estimating the system temperature using both direct measurements and noise analysis.

\subsection{Reading the SRT Data}

In this analysis, Python was used to read the SRT data from the \texttt{.rad} file and extract the system temperature ($T_{\text{sys}}$). The $T_{\text{sys}}$ value is calculated using equation (1), which is handled internally by the SRT during the \texttt{noisecal} command. For this particular observation, the extracted $T_{\text{sys}}$ value was 849 K. This value serves as a reference point for comparing the system's noise characteristics during the observation. \\

Additionally, other crucial parameters were obtained from the \texttt{.rad} file, including the starting frequency, frequency channel width, and the total number of frequency channels. Specifically, the starting frequency was recorded as 1419.79 MHz, with a channel width of 0.0078125 MHz, and 156 total frequency channels were used in the spectral analysis. The observation targeted a specific position in the Milky Way, at a Galactic longitude of 110° and latitude 0°, focusing on the outer regions of the Galactic plane. \\

Throughout the observation, a total of 78 scans were recorded at the selected Galactic coordinates. These scans were integrated to improve the signal-to-noise ratio, allowing for a clearer detection of the 21-cm hydrogen emission line. The multiple scans provide a more stable representation of the hydrogen signal by averaging out random noise present in individual scans.

\subsection{Averaging the HI Spectrum}

In this step, we averaged all the HI spectra recorded at our selected Galactic coordinates. The averaging process results in a spectrum that is representative of the hydrogen emission at this location in the Milky Way.

The averaged HI spectrum was plotted as a function of frequency, with the antenna temperature (\(T_a\)) on the y-axis and frequency channels on the x-axis (see Figure \ref{fig:intensity_over_frequency}). Antenna temperature is a measure of the power detected by the radio telescope and is directly related to the strength of the hydrogen emission signal. This plot provides an initial view of the HI emission across the frequency range centered around 1420.4 MHz, corresponding to the 21-cm line of neutral hydrogen (\(H\textsc{i}\)).

\begin{figure}[h]
    \centering
    \includegraphics[width=0.45\textwidth]{intensity_over_frequency.png}
    \caption{Averaged HI spectrum (in units of Antenna Temperature) vs. Frequency channels.}
    \label{fig:intensity_over_frequency}
\end{figure}

To interpret the averaged spectrum in terms of the velocity of hydrogen gas, we converted the frequency data into Topocentric Radial Velocity using the non-relativistic Doppler shift equation:
\[
v_r = c \times \frac{f_0 - f}{f_0}
\]
where \(v_r\) is the radial velocity, \(c\) is the speed of light, \(f\) is the observed frequency, and \(f_0\) is the rest frequency of the hydrogen 21-cm line (1420.405 MHz). This conversion allows us to map the frequency shift observed in the HI spectrum to the velocity of hydrogen gas relative to the Earth. The resulting plot, shown in Figure \ref{fig:intensity_over_velocity}, provides insights into the velocity distribution of neutral hydrogen gas along the line of sight at our selected Galactic position. \\

\begin{figure}[h]
    \centering
    \includegraphics[width=0.45\textwidth]{intensity_over_velocity.png}
    \caption{Averaged HI Spectrum (in units of Antenna Temperature) vs. Topocentric Radial Velocity.}
    \label{fig:intensity_over_velocity}
\end{figure}

To further isolate the HI signal, we performed a baseline subtraction. This involves fitting a linear polynomial to frequency channels where no significant HI emission is observed, allowing us to model the spectral baseline. The baseline represents contributions from system noise and other non-astronomical sources. Subtracting this baseline from the averaged spectrum helps in removing unwanted background noise, thus highlighting the true HI signal. \\

After the subtraction, the baseline-subtracted HI spectrum was plotted as a function of Topocentric Radial Velocity, as shown in Figure \ref{fig:baseline_subtracted}. The resulting spectrum now provides a clearer view of the hydrogen line emission, with the baseline noise effectively removed. This step is crucial for accurate analysis, as it allows us to focus on the spectral features that are directly associated with the motion and distribution of neutral hydrogen in the Milky Way.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.45\textwidth]{baseline_int_over_velocity.png}
    \caption{Baseline-Subtracted Averaged HI Spectrum vs. Topocentric Radial Velocity.}
    \label{fig:baseline_subtracted}
\end{figure}

By averaging the HI spectra and performing baseline subtraction, we obtain a more refined view of the hydrogen gas's velocity structure along our line of sight. This process allows us to compare the observed emission with data from professional the Leiden-Dwingeloo Survey, providing an absolute calibration reference for our measurements.

\subsection{Comparison with the LDS Data}

The next step in the analysis involves comparing our observations with the HI data from the Leiden-Dwingeloo Survey (LDS). The LDS data is organized in a data cube format, where each slice of the cube represents a different velocity channel, and each pixel within a slice corresponds to a specific position in Galactic longitude and latitude. \\

A data cube is a three-dimensional array of spectral line data, with two spatial dimensions (Galactic longitude and latitude) and one spectral dimension (velocity). To extract the HI spectrum corresponding to our observations, we identified the pixel location that matches the Galactic longitude of 110° and latitude of 0°. Then, we averaged the HI spectra from a 12 x 12 pixel area centered on this position to match the lower angular resolution of the SRT. This averaging ensures that we are comparing spectra that are spatially consistent between the LDS and SRT datasets. The pixel corresponding to a given Galactic coordinate is determined using the equation:
\[
\text{pixel} = \text{center pixel} + \frac{\text{coordinate - center value}}{\text{delta}}
\]
where ``center pixel" refers to the reference pixel value from the LDS header, ``center value" is the Galactic coordinate at the reference pixel, and ``delta" is the increment per pixel. Using this method, we extracted the HI spectrum at the target coordinates. The extracted LDS HI spectrum is plotted as a function of radial velocity, similar to our SRT spectrum, allowing for a direct comparison. This is shown in the figure \ref{12x12}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.45\textwidth]{12x12_lds.png}
    \caption{HI Brightness Temperature as a function of Radial Velocity from LDS averaged over a 12 x 12 pixel region.}
    \label{12x12}
\end{figure}

To assess the accuracy of our calibration, we compared the peak intensity of the LDS HI spectrum to the peak intensity from our SRT observations. A scaling factor, \(\eta\), was calculated using the equation:
\[
\eta = \frac{\text{Peak Intensity (LDS)}}{\text{Peak Intensity (SRT Observations)}}
\]
This factor represents the adjustment needed to match the SRT data to the LDS data, providing an estimate of the main beam efficiency (scaling factor) of the SRT. We applied this scaling factor to our SRT spectrum to align it with the LDS spectrum. \\

The comparison between the scaled SRT spectrum and the LDS spectrum shows a closer match, particularly in the overall shape and peak values of the HI signal. This confirms that our calibration procedure is effective in adjusting for differences between the datasets. The main beam efficiency is found to be 2.819, indicating the relative adjustment required to align the SRT data with the higher-resolution LDS survey. \\

The calibrated data provided a closer alignment with the LDS survey, allowing us to verify the accuracy of our SRT observations. This comparison is crucial for ensuring that our observations are consistent with established datasets, validating the reliability of our measurements. Figure \ref{unscaled} shows a comparison between the unscaled SRT observations and the LDS data while Figure \ref{scaled} shows a comparison between the scaled SRT observations and the LDS data.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.45\textwidth]{unscaled_comparision.png}
    \caption{Comparison of Unscaled Observations and LDS Spectrum: The initial comparison before applying the scaling factor.}
    \label{unscaled}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.45\textwidth]{scaled_comparision.png}
    \caption{Comparison of Scaled Observations and LDS Spectrum: The plot shows the scaled SRT HI spectrum overlaid with the LDS HI spectrum.}
    \label{scaled}
\end{figure}

\subsection{Estimating System Temperature ($T_{\text{sys}}$)}

In this part of the analysis, we aimed to derive a new estimate for the system temperature ($T_{\text{sys}}$) using the radiometer equation (Equation (3)). The radiometer equation relates the RMS noise level of the observed data to the system temperature, providing an important measure of the noise characteristics of the system. This estimate serves as a benchmark to verify the accuracy of the $T_{\text{sys}}$ value directly obtained from the SRT during data acquisition.  \\

To achieve this, we measured the root-mean-square (RMS) noise of the baseline-subtracted averaged HI spectrum, focusing on a range of channels that do not contain any significant HI signal using Equation (2). This ensured that the derived noise value represented the inherent noise properties of the system without contamination from astronomical sources. For this analysis, we considered frequency channels corresponding to topocentric radial velocities between 30 km/s and 100 km/s, where the HI emission was minimal. \\

Next, we accounted for the effective integration time, which is crucial in applying the radiometer equation. This adjustment accounts for the overhead time required for the SRT to record and transfer data during the observation. Thus, the effective integration time is calculated as 40 seconds.
The radiometer equation used for estimating $T_{\text{sys}}$ is obtained by rearranging Equation (3):
\[
T_{\text{sys, calculated}} = \sigma_{\text{rms}} \sqrt{\Delta \nu \cdot t}
\]

where:
\begin{itemize}
    \item $\sigma_{\text{rms}}$: The measured RMS noise of the baseline-subtracted spectrum, calculated as 5.19 K.
    \item $\Delta \nu$: The frequency resolution of the SRT, given as 0.0078125 MHz.
    \item $t$: The adjusted integration time, calculated as 40 seconds.
\end{itemize}

Using this equation, we calculated a $T_{\text{sys}}$ value of approximately 2900 K. This is significantly higher than the initial value of 849 K reported by the SRT software. The discrepancy between the estimated and recorded values suggests a potential issue with the SRT's noise diode calibration, indicating that the diode might not be operating properly during the observation.

\subsection{Radiometer Test}

This step evaluates the performance of our SRT receiver in comparison to an ideal radiometer by varying the number of scans used to produce the averaged HI spectrum. The primary objective is to observe how the RMS noise level changes when different numbers of scans are averaged. This helps us understand the SRT’s deviation from the expected behavior of an ideal radiometer. \\

For our analysis, we used a total of 78 scans at the selected Galactic coordinates. We computed the averaged HI spectra for subsets of these scans, specifically for 5, 10, 20, 40, 60, and 78 scans. Each of these averaged spectra was scaled by the previously determined main beam efficiency scaling factor. \\

To calculate the noise level for each subset, we measured the RMS noise using the baseline-subtracted spectra over a range of velocities without significant HI emission (from 24 to 114 km/s). The RMS noise values for each subset were calculated using Equation (2). \\

The results are plotted in Figure~\ref{fig:rms_noise_vs_scans}, showing the relationship between the RMS noise and the number of scans averaged. As expected for an ideal radiometer, the RMS noise decreases as the number of scans increases, indicating that averaging more data reduces random noise in the signal. \\

\begin{figure}[h]
    \centering
    \includegraphics[width=0.45\textwidth]{changing_rms.png}
    \caption{RMS noise as a function of the number of scans used for integration. The decreasing trend is consistent with radiometric principles, demonstrating that averaging more scans reduces the noise level.}
    \label{fig:rms_noise_vs_scans}
\end{figure}

This analysis provides insight into the SRT's behavior compared to an ideal radiometer. The trend of decreasing noise with increasing scans aligns with theoretical expectations, although the exact noise levels may differ due to instrument-specific factors like the SRT’s electronics and data collection process.

\section{Conclusions}

In this lab, we conducted a detailed analysis of HI spectra using the Small Radio Telescope (SRT) and compared the results with the Leiden/Argentine/Bonn (LDS) survey data to evaluate the accuracy of our observations. The key steps involved reading the SRT data, extracting crucial parameters such as the system temperature ($T_{\text{sys}}$) of 849 K, and producing averaged HI spectra at Galactic coordinates (longitude 110°, latitude 0°). Using Python, we processed the SRT data, performed baseline subtraction, and converted frequencies into topocentric radial velocities for a more accurate representation of hydrogen gas distributions. \\

The comparison between the averaged HI spectrum from the SRT and the LDS data allowed us to derive a scaling factor of approximately 2.819, representing the main beam efficiency. Applying this factor to our data enabled a better match between the SRT and the high-resolution LDS spectra. We also calculated the RMS noise for our observations; this being 5.19. Additionally, using the radiometer equation, we obtained a recalculated $T_{\text{sys}}$ value of approximately 2900 K, which differed significantly from the SRT-reported value. This discrepancy is likely due to calibration challenges and instrumental factors, such as issues with the SRT’s diode. \\

A radiometer test was also performed to assess the SRT’s performance relative to an ideal radiometer. By varying the number of scans used to produce the averaged spectra, we observed that the RMS noise decreased as the number of scans increased, in accordance with radiometric principles. This behavior confirmed that averaging more data reduces random noise, although specific deviations were noted, likely due to the unique characteristics of the SRT setup.

\subsection{Uncertainty Analysis}

Random uncertainties in this analysis stem primarily from noise in the SRT data due to thermal fluctuations and atmospheric conditions. These were mitigated by averaging multiple scans, reducing the influence of random variations. The decreasing RMS noise with increasing scans, as observed in the radiometer test, reflects this reduction. However, residual random noise remains, impacting the precision of the baseline-subtracted HI spectrum. \\

Systematic uncertainties were present in the calibration process and in the determination of $T_{\text{sys}}$. The significant difference between the reported $T_{\text{sys}}$ and the calculated value suggests systematic errors, possibly due to issues with the SRT’s diode or variations in the SRT’s sensitivity. Additionally, the process of scaling the SRT data to match the LDS spectra introduced uncertainties related to the accuracy of the scaling factor. The alignment between the scaled spectrum and the LDS data indicates a reasonable calibration, but discrepancies in peak values highlight potential systematic biases in the SRT measurements.

\subsection{Future Improvements}

To enhance the accuracy and reliability of similar observations in the future, several improvements could be implemented. First, refining the calibration process by using more reference sources with well-known properties would help minimize systematic errors in $T_{\text{sys}}$, addressing discrepancies between the reported and calculated values of $T_{\text{sys}}$. Additionally, extending the duration of observations and increasing the number of scans would further reduce random noise, as suggested by the radiometer equation. More data would improve the precision of the averaged spectra and reduce fluctuations in the baseline. Implementing advanced noise reduction techniques, such as adaptive filtering or using more sophisticated baseline subtraction methods, could also enhance the quality of the spectra, especially for weaker signals. Regular diagnostics and maintenance of the SRT components, particularly the diode and receiver system, would help identify and resolve issues affecting the sensitivity of the telescope, leading to more consistent measurements. Finally, comparing the SRT data with other high-resolution surveys besides the LDS dataset could provide further validation of the observations and the calibration process, offering a more robust assessment of the SRT data. \\

Overall, this analysis demonstrated the importance of calibration and noise reduction in radio astronomical observations. While the SRT data showed deviations from ideal behavior, the comparison with LDS data provided valuable insights into the accuracy of our measurements and the limitations of the SRT. The systematic and random uncertainties identified suggest areas for improvement in future observations and calibrations.


\begin{thebibliography}{}

\bibitem[Astro465(2024)]{Astro4652024}
Astro465 Lab Manual, University of Wisconsin--Madison, 2024, available through the course Canvas page.

\bibitem[Astro465Slides(2024)]{Astro465Slides2024}
Astro465 Class Slides, University of Wisconsin--Madison, 2024, available through the course Canvas page.

\begin{flushright}
\begin{flushleft}
\bibitem[Hartmann \& Burton(1997)]{Hartmann1997}
Hartmann, D., \& Burton, W. B. 1997, \textit{The Leiden/Dwingeloo Survey of Emission from Galactic HI}, Available at \url{https://ui.adsabs.harvard.edu/abs/1994Ap%26SS.217..189B/abstract}.
\end{flushleft}
\end{flushright}

\end{thebibliography}


\end{document}

